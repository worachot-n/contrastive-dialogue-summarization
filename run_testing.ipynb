{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfGuU-bBsu3J",
    "outputId": "e19cfe61-e01a-4e25-f7d9-d5f86adeedfd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "id": "BDHK-dEEsu3P",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "import random\n",
    "import json\n",
    "\n",
    "import datasets\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from filelock import FileLock\n",
    "from transformers import AdamW, get_scheduler, set_seed\n",
    "\n",
    "from transformers.file_utils import is_offline_mode\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from args import parse_args\n",
    "from data_loader import raw_data_loader, data_processor\n",
    "from model_loader import model_loader\n",
    "from rouge_s import py_rouge_scores\n",
    "from utils import label_smoothed_nll_loss, postprocess_text, cosine_embedding_loss\n",
    "\n",
    "from transformers import (\n",
    "    MODEL_MAPPING,\n",
    "    SchedulerType,\n",
    ")\n",
    "\n",
    "# You should update this to your particular problem to have better documentation of `model_type`\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zI3YKK_psu3Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import SchedulerType\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AD495S_Dsu3S",
    "outputId": "ac6a6306-5a6b-4f3b-ca58-d8d40e6c20cf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--debug'], dest='debug', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Use the debug mode or not', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"bart\")\n",
    "parser.add_argument(\n",
    "    \"--train_file\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"A csv or a json file containing the training data.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--validation_file\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"A csv or a json file containing the validation data.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--test_file\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"A csv or a json file containing the test data.\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--ignore_pad_token_for_loss\",\n",
    "    type=bool,\n",
    "    default=True,\n",
    "    help=\"Whether to ignore the tokens corresponding to \"\n",
    "    \"padded labels in the loss computation or not.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_source_length\",\n",
    "    type=int,\n",
    "    default=1024,\n",
    "    help=\"The maximum total input sequence length after \"\n",
    "    \"tokenization.Sequences longer than this will be truncated, sequences shorter will be padded.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--source_prefix\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"A prefix to add before every source text \" \"(useful for T5 models).\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--preprocessing_num_workers\",\n",
    "    type=int,\n",
    "    default=None,\n",
    "    help=\"The number of processes to use for the preprocessing.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--overwrite_cache\",\n",
    "    type=bool,\n",
    "    default=None,\n",
    "    help=\"Overwrite the cached training and evaluation sets\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--min_target_length\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"The minimal total sequence length for target text\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_target_length\",\n",
    "    type=int,\n",
    "    default=128,\n",
    "    help=\"The maximum total sequence length for target text after \"\n",
    "    \"tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "    \"during ``evaluate`` and ``predict``.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--length_penalty\",\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    help=\"large - longer sequence, small - shorter sequence\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_beams\",\n",
    "    type=int,\n",
    "    default=4,\n",
    "    help=\"Number of beams to use for evaluation. This argument will be \"\n",
    "    \"passed to ``model.generate``, which is used during ``evaluate`` and ``predict``.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--pad_to_max_length\",\n",
    "    action=\"store_true\",\n",
    "    help=\"If passed, pad all samples to `max_length`. Otherwise, dynamic padding is used.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_name_or_path\",\n",
    "    type=str,\n",
    "    help=\"Path to pretrained model or model identifier from huggingface.co/models.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--config_name\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"Pretrained config name or path if not the same as model_name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tokenizer_name\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--text_column\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"The name of the column in the datasets containing the full texts (for summarization).\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--summary_column\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"The name of the column in the datasets containing the summaries (for summarization).\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_slow_tokenizer\",\n",
    "    action=\"store_true\",\n",
    "    help=\"If passed, will use a slow tokenizer (not backed by the ðŸ¤— Tokenizers library).\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--per_device_train_batch_size\",\n",
    "    type=int,\n",
    "    default=8,\n",
    "    help=\"Batch size (per device) for the training dataloader.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--per_device_eval_batch_size\",\n",
    "    type=int,\n",
    "    default=8,\n",
    "    help=\"Batch size (per device) for the evaluation dataloader.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--per_device_test_batch_size\",\n",
    "    type=int,\n",
    "    default=8,\n",
    "    help=\"Batch size (per device) for the evaluation dataloader.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\",\n",
    "    type=float,\n",
    "    default=5e-5,\n",
    "    help=\"Initial learning rate (after the potential warmup period) to use.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weight_decay\", type=float, default=0.0, help=\"Weight decay to use.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_train_epochs\",\n",
    "    type=int,\n",
    "    default=3,\n",
    "    help=\"Total number of training epochs to perform.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_train_steps\",\n",
    "    type=int,\n",
    "    default=None,\n",
    "    help=\"Total number of training steps to perform. If provided, overrides num_train_epochs.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler_type\",\n",
    "    type=SchedulerType,\n",
    "    default=\"linear\",\n",
    "    help=\"The scheduler type to use.\",\n",
    "    choices=[\n",
    "        \"linear\",\n",
    "        \"cosine\",\n",
    "        \"cosine_with_restarts\",\n",
    "        \"polynomial\",\n",
    "        \"constant\",\n",
    "        \"constant_with_warmup\",\n",
    "    ],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_warmup_steps\",\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help=\"Number of steps for the warmup in the lr scheduler.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_dir\", type=str, default=None, help=\"Where to store the final model.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--cache_dir\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"Cache directory for pre-trained models.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\", type=int, default=None, help=\"A seed for reproducible training.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_type\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"Model type to use if training from scratch.\",\n",
    "    choices=MODEL_TYPES,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--len_input\",\n",
    "    type=str,\n",
    "    default=\"no\",\n",
    "    help=\"Use the ctrlen model or not\",\n",
    "    choices=(\n",
    "        \"no\",\n",
    "        \"topic\",\n",
    "        \"length\",\n",
    "        \"topic-length\",\n",
    "        \"topic-speaker-length\",\n",
    "    ),\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--len_output\",\n",
    "    type=str,\n",
    "    default=\"no\",\n",
    "    help=\"Use the ctrlen model or not\",\n",
    "    choices=(\"no\"),\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ctrlen_model\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"Use the ctrlen model or not\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--sim_window_size\", type=int, default=5, help=\"window size for computing loss.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--sim_loss\",\n",
    "    type=float,\n",
    "    default=0,\n",
    "    help=\"the loss weight for similarity scores.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--special_len_token_init\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"ways to initialize special token for length (random, zero, token_embs)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--embedding_lr\",\n",
    "    type=float,\n",
    "    default=5e-5,\n",
    "    help=\"Initial learning rate for embedding layers.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--len_start\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"start length.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--len_end\",\n",
    "    type=int,\n",
    "    default=100,\n",
    "    help=\"end length.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_aug\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"whether to perform data augmentation or not\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--pred_len\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"whether to use the golden length or predicted length\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--shuffle\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"whether to shuffle the dataset to balance train/validation/test\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--label_smoothing\",\n",
    "    type=float,\n",
    "    default=0.0,\n",
    "    help=\"hyperparameter for label smoothing.\",\n",
    ")\n",
    "# contrastive\n",
    "parser.add_argument(\n",
    "    \"--contrastive\",\n",
    "    type=str,\n",
    "    default=\"no\",\n",
    "    help=\"Use contrastive or not\",\n",
    "    choices=(\n",
    "        \"no\",\n",
    "        \"top\",\n",
    "        \"tail\",\n",
    "        \"top-tail\",\n",
    "    ),\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--alpha\",\n",
    "    type=float,\n",
    "    default=0.5,\n",
    "    help=\"Initial alpha\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--margin\",\n",
    "    type=float,\n",
    "    default=0.5,\n",
    "    help=\"Initial margin\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--run_test\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"Run for testing\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--debug\",\n",
    "    action=\"store_true\",\n",
    "    default=False,\n",
    "    help=\"Use the debug mode or not\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sizQFLtFsu3T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-nJe4mEqsu3U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.len_input = 'topic-length' \n",
    "args.len_output = 'no'\n",
    "args.output_dir = './output/0'\n",
    "\n",
    "args.train_file = './data/dialogsum/dialogsum.train.jsonl'\n",
    "args.validation_file = './data/dialogsum/dialogsum.dev.jsonl'\n",
    "args.test_file = './data/dialogsum/dialogsum.test.jsonl'\n",
    "args.text_column = 'dialogue'\n",
    "\n",
    "# args.train_file = './data/macdial_flatten/train.json'\n",
    "# args.validation_file = './data/macdial_flatten/val.json'\n",
    "# args.test_file = './data/macdial_flatten/test.json'\n",
    "# args.text_column = 'dialogue'\n",
    "\n",
    "args.summary_column = 'summary'\n",
    "args.model_name_or_path = 'facebook/bart-large'\n",
    "# args.model_name_or_path = 'facebook/bart-large-cnn'\n",
    "args.model_type = 'bart'\n",
    "\n",
    "args.max_target_length = 128\n",
    "args.num_beams = 4\n",
    "args.learning_rate = 5e-5\n",
    "args.weight_decay = 1e-3\n",
    "args.label_smoothing = 0.1\n",
    "args.length_penalty = 1.0\n",
    "args.num_train_epochs = 1\n",
    "args.per_device_train_batch_size = 2\n",
    "args.gradient_accumulation_steps = 32\n",
    "args.per_device_eval_batch_size = 8\n",
    "args.per_device_test_batch_size = 8\n",
    "args.num_warmup_steps = 0\n",
    "\n",
    "# args.max_target_length = 400\n",
    "# args.num_beams = 4\n",
    "# args.learning_rate = 3e-5\n",
    "# args.weight_decay = 1e-3\n",
    "# args.label_smoothing = 0.1\n",
    "# args.length_penalty = 1.0\n",
    "# args.num_train_epochs = 1\n",
    "# args.per_device_train_batch_size = 2\n",
    "# args.gradient_accumulation_steps = 32\n",
    "# args.per_device_eval_batch_size = 8\n",
    "# args.per_device_test_batch_size = 8\n",
    "# args.num_warmup_steps = 500\n",
    "\n",
    "args.cache_dir = './output/cache'\n",
    "args.overwrite_cache = True\n",
    "args.seed = 12345\n",
    "args.contrastive = \"top-tail\"\n",
    "args.alpha = 0.5\n",
    "args.margin = 0.5\n",
    "args.run_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the accelerator. The accelerator will handle device placement for us.\n",
    "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "\n",
    "# Setup logging, we only want one process per machine to log things on the screen.\n",
    "# accelerator.is_local_main_process is only True for one process per machine.\n",
    "if accelerator.is_local_main_process:\n",
    "    device = accelerator.device\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If passed along, set the training seed now.\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process:\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tz2ZuJAMsu3X",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'dialogue', 'summary', 'top_topic_dialogue', 'tail_topic_dialogue']) 1500\n",
      "dict_keys(['id', 'dialogue', 'summary', 'top_topic_dialogue', 'tail_topic_dialogue']) 50\n",
      "dict_keys(['id', 'dialogue', 'summary', 'top_topic_dialogue', 'tail_topic_dialogue']) 150\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = raw_data_loader(args)\n",
    "print(raw_datasets['train'].features.keys(), raw_datasets['train'].num_rows)\n",
    "print(raw_datasets['validation'].features.keys(), raw_datasets['validation'].num_rows)\n",
    "print(raw_datasets['test'].features.keys(), raw_datasets['test'].num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "train_1\n",
      "--------------------\n",
      "dialogue\n",
      "Topic of Summary: vaccines. Length of Summary: 18. Dialogue: #Person1#: Hello Mrs. Parker, how have you been?\n",
      "#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\n",
      "#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\n",
      "#Person2#: What about Rubella and Mumps?\n",
      "#Person1#: Well, I can only give him these for now, and after a couple of weeks I can administer the rest.\n",
      "#Person2#: OK, great. Doctor, I think I also may need a Tetanus booster. Last time I got it was maybe fifteen years ago!\n",
      "#Person1#: We will check our records and I'll have the nurse administer and the booster as well. Now, please hold Ricky's arm tight, this may sting a little.\n",
      "--------------------\n",
      "summary\n",
      "Mrs Parker takes Ricky for his vaccines. Dr. Peters checks the record and then gives Ricky a vaccine.\n",
      "--------------------\n",
      "top_topic_dialogue\n",
      "Topic of Summary: vaccination. Length of Summary: 18. Dialogue: #Person1#: Hello Mrs. Parker, how have you been?\n",
      "#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\n",
      "#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\n",
      "#Person2#: What about Rubella and Mumps?\n",
      "#Person1#: Well, I can only give him these for now, and after a couple of weeks I can administer the rest.\n",
      "#Person2#: OK, great. Doctor, I think I also may need a Tetanus booster. Last time I got it was maybe fifteen years ago!\n",
      "#Person1#: We will check our records and I'll have the nurse administer and the booster as well. Now, please hold Ricky's arm tight, this may sting a little.\n",
      "--------------------\n",
      "tail_topic_dialogue\n",
      "Topic of Summary: David Peckham. Length of Summary: 18. Dialogue: #Person1#: Hello Mrs. Parker, how have you been?\n",
      "#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\n",
      "#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\n",
      "#Person2#: What about Rubella and Mumps?\n",
      "#Person1#: Well, I can only give him these for now, and after a couple of weeks I can administer the rest.\n",
      "#Person2#: OK, great. Doctor, I think I also may need a Tetanus booster. Last time I got it was maybe fifteen years ago!\n",
      "#Person1#: We will check our records and I'll have the nurse administer and the booster as well. Now, please hold Ricky's arm tight, this may sting a little.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for feature in raw_datasets['train'].features:\n",
    "    print(feature)\n",
    "    # if feature == \"topic\" or feature == \"synonym_topic\" or feature == \"random_topic\":\n",
    "    #     print(raw_datasets['train'][feature][num])\n",
    "    print(raw_datasets['train'][feature][num])\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9y_Gspbqsu3Y",
    "outputId": "aac050f9-7369-4b98-f0fa-343cfa962896",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/vocab.json\n",
      "loading file merges.txt from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/merges.txt\n",
      "loading file tokenizer.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50265. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Configuration saved in ./output/0/start/config.json\n",
      "Configuration saved in ./output/0/start/generation_config.json\n",
      "Model weights saved in ./output/0/start/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/0/start/tokenizer_config.json\n",
      "Special tokens file saved in ./output/0/start/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "config, tokenizer, model = model_loader(accelerator, logger, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n",
      "['bos_token', 'eos_token', 'unk_token', 'sep_token', 'pad_token', 'cls_token', 'mask_token', 'additional_special_tokens']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(model.vocab_size)\n",
    "print(tokenizer.SPECIAL_TOKENS_ATTRIBUTES)\n",
    "print(tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "d0098c03b82d48c9acdc684fbbf54567",
      "fa32d34f467944f2aaf4a13fdf7a0cf2",
      "e3bc145889c94fc3974e88e46863db89",
      "ddbc6421b4cf487d92cc53fb0ae6f634",
      "13bb8c4b9a154bb99c4d38cd2edb631c",
      "5a2947306125452c8c25c12e54dc6656",
      "326356876bd540778d188c41673e04f5",
      "542a00a050384f5f8f3f7354eb527336",
      "a91a8c5870234ab3bdd0132addb34a20",
      "9c182b108efa471994186923f10871a8",
      "c34934bec45646a8b2ac76c60dc124d5",
      "24272444846441638d4836fd835562dc",
      "78f6c1bca77640ca92bd87d5995fced5",
      "81669ba2443a489cb535c508333dc974",
      "47ddb2c2d8fa4c278c9d514ace68341f",
      "b842e08bc1ca45ee99a868d1dfa4d0db",
      "4616558f0ebd466babad0202bc55824d",
      "9a4ed651601f4a29b763eed10afafc16",
      "368a820467ad4f4d8198932125f0d357",
      "f5ece15e08e44905a09d9a2e988a4be4",
      "932e4629e7f340c2a5b64d095c46bf4d",
      "a26c7dc74d71494787fd32d560594b38",
      "90b25ecb208546f9938652c360ef7a5e",
      "852ba2b2a4fd4bbe80a2ecd9c9f6b5fb",
      "7f1272db213a4121ae95b5e41061d964",
      "a3ad3e93702041d89b6f505ec6d37411",
      "ffcb842d99954cdcaa8fb78e8e3b2215",
      "b1a15a93c5e746888806f8dd19cf6889",
      "35f50d433dc14aa28cf0f5a039f7cb87",
      "e69f5057741b46dba3ebb186ef85c6db",
      "14052c5abfad4231a0d4c8d0e0395a01",
      "3bad8094e9124ab391d945edf4ccca2f",
      "31409e259c8b4ee7899035ea4ba3f140"
     ]
    },
    "id": "BNku9V-ssu3Y",
    "outputId": "ab678f18-5bfa-4b54-fbb4-cac959f8edcb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5332bb6f03f40d883776a4a90ff03d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735777ca03114003857673fffb1a74e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c050d2a563f46b9bcf280bec6627917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/14/2024 17:51:08 - INFO - __main__ - Sample 871 of the training set: {'input_ids': [0, 48931, 9, 19584, 35, 489, 2245, 4, 41852, 9, 19584, 35, 389, 4, 33854, 35, 849, 41761, 134, 10431, 35, 1832, 47, 3529, 10, 319, 9, 2245, 689, 116, 50118, 10431, 41761, 176, 10431, 35, 23570, 19, 2245, 689, 6, 21250, 689, 95, 17893, 98, 203, 357, 4, 178, 6992, 6, 38, 679, 114, 47, 697, 10, 614, 3992, 3126, 8, 32, 2171, 6, 47, 64, 120, 409, 19, 4441, 3046, 47, 101, 4, 85, 18, 70, 11, 5, 1508, 4, 50118, 10431, 41761, 134, 10431, 35, 370, 33, 5, 477, 4, 38, 206, 1668, 16, 1726, 30, 55, 4022, 87, 30, 5, 383, 52, 14623, 4, 993, 205, 383, 47, 197, 860, 32, 32900, 8132, 10580, 6, 3418, 7666, 8, 25610, 4147, 7363, 4, 50118, 10431, 41761, 176, 10431, 35, 653, 18, 780, 59, 209, 383, 116, 50118, 10431, 41761, 134, 10431, 35, 18515, 8132, 10580, 16, 182, 205, 13, 14340, 11190, 9436, 11, 110, 29294, 142, 24, 18, 182, 41314, 4, 3962, 7666, 16, 239, 11, 21060, 98, 24, 18, 205, 13, 110, 29294, 8, 24, 18, 239, 11, 8276, 8, 19701, 12, 100, 206, 24, 18, 67, 24867, 906, 87, 2340, 7666, 4, 17514, 4147, 7363, 18, 205, 142, 24, 18, 67, 4066, 11, 8276, 6, 26656, 8, 16, 67, 41314, 4, 1806, 33, 57, 442, 25610, 4147, 7363, 13, 1583, 9, 107, 8, 114, 47, 33, 24, 358, 183, 6, 110, 29294, 40, 28, 203, 55, 5668, 4, 50118, 10431, 41761, 176, 10431, 35, 4557, 4, 38, 437, 164, 7, 1407, 110, 2949, 8, 3495, 159, 7, 5, 12647, 235, 122, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'top_topic_inputs': [0, 48931, 9, 19584, 35, 2245, 689, 4, 41852, 9, 19584, 35, 389, 4, 33854, 35, 849, 41761, 134, 10431, 35, 1832, 47, 3529, 10, 319, 9, 2245, 689, 116, 50118, 10431, 41761, 176, 10431, 35, 23570, 19, 2245, 689, 6, 21250, 689, 95, 17893, 98, 203, 357, 4, 178, 6992, 6, 38, 679, 114, 47, 697, 10, 614, 3992, 3126, 8, 32, 2171, 6, 47, 64, 120, 409, 19, 4441, 3046, 47, 101, 4, 85, 18, 70, 11, 5, 1508, 4, 50118, 10431, 41761, 134, 10431, 35, 370, 33, 5, 477, 4, 38, 206, 1668, 16, 1726, 30, 55, 4022, 87, 30, 5, 383, 52, 14623, 4, 993, 205, 383, 47, 197, 860, 32, 32900, 8132, 10580, 6, 3418, 7666, 8, 25610, 4147, 7363, 4, 50118, 10431, 41761, 176, 10431, 35, 653, 18, 780, 59, 209, 383, 116, 50118, 10431, 41761, 134, 10431, 35, 18515, 8132, 10580, 16, 182, 205, 13, 14340, 11190, 9436, 11, 110, 29294, 142, 24, 18, 182, 41314, 4, 3962, 7666, 16, 239, 11, 21060, 98, 24, 18, 205, 13, 110, 29294, 8, 24, 18, 239, 11, 8276, 8, 19701, 12, 100, 206, 24, 18, 67, 24867, 906, 87, 2340, 7666, 4, 17514, 4147, 7363, 18, 205, 142, 24, 18, 67, 4066, 11, 8276, 6, 26656, 8, 16, 67, 41314, 4, 1806, 33, 57, 442, 25610, 4147, 7363, 13, 1583, 9, 107, 8, 114, 47, 33, 24, 358, 183, 6, 110, 29294, 40, 28, 203, 55, 5668, 4, 50118, 10431, 41761, 176, 10431, 35, 4557, 4, 38, 437, 164, 7, 1407, 110, 2949, 8, 3495, 159, 7, 5, 12647, 235, 122, 4, 2], 'tail_topic_inputs': [0, 48931, 9, 19584, 35, 1994, 7, 951, 4, 41852, 9, 19584, 35, 389, 4, 33854, 35, 849, 41761, 134, 10431, 35, 1832, 47, 3529, 10, 319, 9, 2245, 689, 116, 50118, 10431, 41761, 176, 10431, 35, 23570, 19, 2245, 689, 6, 21250, 689, 95, 17893, 98, 203, 357, 4, 178, 6992, 6, 38, 679, 114, 47, 697, 10, 614, 3992, 3126, 8, 32, 2171, 6, 47, 64, 120, 409, 19, 4441, 3046, 47, 101, 4, 85, 18, 70, 11, 5, 1508, 4, 50118, 10431, 41761, 134, 10431, 35, 370, 33, 5, 477, 4, 38, 206, 1668, 16, 1726, 30, 55, 4022, 87, 30, 5, 383, 52, 14623, 4, 993, 205, 383, 47, 197, 860, 32, 32900, 8132, 10580, 6, 3418, 7666, 8, 25610, 4147, 7363, 4, 50118, 10431, 41761, 176, 10431, 35, 653, 18, 780, 59, 209, 383, 116, 50118, 10431, 41761, 134, 10431, 35, 18515, 8132, 10580, 16, 182, 205, 13, 14340, 11190, 9436, 11, 110, 29294, 142, 24, 18, 182, 41314, 4, 3962, 7666, 16, 239, 11, 21060, 98, 24, 18, 205, 13, 110, 29294, 8, 24, 18, 239, 11, 8276, 8, 19701, 12, 100, 206, 24, 18, 67, 24867, 906, 87, 2340, 7666, 4, 17514, 4147, 7363, 18, 205, 142, 24, 18, 67, 4066, 11, 8276, 6, 26656, 8, 16, 67, 41314, 4, 1806, 33, 57, 442, 25610, 4147, 7363, 13, 1583, 9, 107, 8, 114, 47, 33, 24, 358, 183, 6, 110, 29294, 40, 28, 203, 55, 5668, 4, 50118, 10431, 41761, 176, 10431, 35, 4557, 4, 38, 437, 164, 7, 1407, 110, 2949, 8, 3495, 159, 7, 5, 12647, 235, 122, 4, 2], 'labels': [0, 10431, 41761, 134, 10431, 8, 849, 41761, 176, 10431, 258, 206, 1668, 16, 1726, 30, 55, 4022, 87, 689, 4, 849, 41761, 134, 10431, 42353, 29, 4441, 32900, 8132, 10580, 6, 3418, 7666, 8, 25610, 4147, 7363, 142, 51, 33, 4066, 17792, 4, 849, 41761, 176, 10431, 40, 860, 106, 4, 2]}.\n",
      "/home/worachotn/.local/lib/python3.10/site-packages/accelerate/accelerator.py:527: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader, processed_dataset = data_processor(logger, args, accelerator, raw_datasets, tokenizer, model)\n",
    "train_dataloader, eval_dataloader, test_dataloader = dataloader\n",
    "train_dataset, _, _ = processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HD4JVgBRFOlA",
    "outputId": "8915a69c-5801-4da1-9053-00859e286af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'top_topic_inputs', 'tail_topic_inputs', 'labels']) 1500\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.features.keys(), train_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "P7kZdADiv0dl",
    "outputId": "c7280b18-3968-4d9a-a408-1246043ea647",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 360])\n",
      "index:  0\n",
      "<s>Topic of Summary: search for books. Length of Summary: 37. Dialogue: #Person1#: Sir, you've been using the online catalogue for quite a while. Is there anything I can do to help you?\n",
      "#Person2#: Well, I've got to write a paper about Hollywood in the 30s and 40s, and I'm really struggling. There are hundreds of books, and I just don't know where to begin.\n",
      "#Person1#: Your topic sounds pretty big. Why don't you narrow it down to something like.., uh... the history of the studios during that time?\n",
      "#Person2#: You know, I was thinking about doing that, but more than 30 books came up when I typed in'movie studios'.\n",
      "#Person1#: You could cut that down even further by listing the specific years you want. Try adding '1930s' or '1940s' or maybe 'Golden Age'.\n",
      "#Person2#: 'Golden Age' is a good idea, Let me type that in. Hey, look, just 6 books this time That's a lot better.\n",
      "#Person1#: Oh, another thing you might consider. Have you tried looking for any magazines or newspaper articles?\n",
      "#Person2#: No, I've only been searching for books.\n",
      "#Person1#: Well, you can look up magazine articles in the Reader's Guide to Periodical Literature.\n",
      "#Person2#: Okay, I think I'll get started with these books and then I'll go over the magazines.\n",
      "#Person1#: If you need any help, I'll be over at the Reference Desk.\n",
      "#Person2#: Great, thanks a lot.</s>\n",
      "index:  1\n",
      "<s>Topic of Summary: English idioms. Length of Summary: 11. Dialogue: #Person1#: Are there many idioms in English?\n",
      "#Person2#: There are hundreds and hundreds. English is particularly rich in idiomatic expressions.\n",
      "#Person1#: Can you give us an example?\n",
      "#Person2#: I'll look up the rate. To look up doesn't mean to look high into the sky or to look at the roof. It means to search for and find some information.\n",
      "#Person1#: What about the expression'goodbye '? Is that an idiom?\n",
      "#Person2#: That is just a natural, grammatical English expression. It has a direct translation in other languages.\n",
      "#Person1#: This is interesting, Ms. Parker.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  2\n",
      "<s>Topic of Summary: tried looking magazines. Length of Summary: 37. Dialogue: #Person1#: Sir, you've been using the online catalogue for quite a while. Is there anything I can do to help you?\n",
      "#Person2#: Well, I've got to write a paper about Hollywood in the 30s and 40s, and I'm really struggling. There are hundreds of books, and I just don't know where to begin.\n",
      "#Person1#: Your topic sounds pretty big. Why don't you narrow it down to something like.., uh... the history of the studios during that time?\n",
      "#Person2#: You know, I was thinking about doing that, but more than 30 books came up when I typed in'movie studios'.\n",
      "#Person1#: You could cut that down even further by listing the specific years you want. Try adding '1930s' or '1940s' or maybe 'Golden Age'.\n",
      "#Person2#: 'Golden Age' is a good idea, Let me type that in. Hey, look, just 6 books this time That's a lot better.\n",
      "#Person1#: Oh, another thing you might consider. Have you tried looking for any magazines or newspaper articles?\n",
      "#Person2#: No, I've only been searching for books.\n",
      "#Person1#: Well, you can look up magazine articles in the Reader's Guide to Periodical Literature.\n",
      "#Person2#: Okay, I think I'll get started with these books and then I'll go over the magazines.\n",
      "#Person1#: If you need any help, I'll be over at the Reference Desk.\n",
      "#Person2#: Great, thanks a lot.</s>\n",
      "index:  3\n",
      "<s>Topic of Summary: english expression. Length of Summary: 11. Dialogue: #Person1#: Are there many idioms in English?\n",
      "#Person2#: There are hundreds and hundreds. English is particularly rich in idiomatic expressions.\n",
      "#Person1#: Can you give us an example?\n",
      "#Person2#: I'll look up the rate. To look up doesn't mean to look high into the sky or to look at the roof. It means to search for and find some information.\n",
      "#Person1#: What about the expression'goodbye '? Is that an idiom?\n",
      "#Person2#: That is just a natural, grammatical English expression. It has a direct translation in other languages.\n",
      "#Person1#: This is interesting, Ms. Parker.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  4\n",
      "<s>Topic of Summary: a birthday gift. Length of Summary: 37. Dialogue: #Person1#: Sir, you've been using the online catalogue for quite a while. Is there anything I can do to help you?\n",
      "#Person2#: Well, I've got to write a paper about Hollywood in the 30s and 40s, and I'm really struggling. There are hundreds of books, and I just don't know where to begin.\n",
      "#Person1#: Your topic sounds pretty big. Why don't you narrow it down to something like.., uh... the history of the studios during that time?\n",
      "#Person2#: You know, I was thinking about doing that, but more than 30 books came up when I typed in'movie studios'.\n",
      "#Person1#: You could cut that down even further by listing the specific years you want. Try adding '1930s' or '1940s' or maybe 'Golden Age'.\n",
      "#Person2#: 'Golden Age' is a good idea, Let me type that in. Hey, look, just 6 books this time That's a lot better.\n",
      "#Person1#: Oh, another thing you might consider. Have you tried looking for any magazines or newspaper articles?\n",
      "#Person2#: No, I've only been searching for books.\n",
      "#Person1#: Well, you can look up magazine articles in the Reader's Guide to Periodical Literature.\n",
      "#Person2#: Okay, I think I'll get started with these books and then I'll go over the magazines.\n",
      "#Person1#: If you need any help, I'll be over at the Reference Desk.\n",
      "#Person2#: Great, thanks a lot.</s>\n",
      "index:  5\n",
      "<s>Topic of Summary: coffee. Length of Summary: 11. Dialogue: #Person1#: Are there many idioms in English?\n",
      "#Person2#: There are hundreds and hundreds. English is particularly rich in idiomatic expressions.\n",
      "#Person1#: Can you give us an example?\n",
      "#Person2#: I'll look up the rate. To look up doesn't mean to look high into the sky or to look at the roof. It means to search for and find some information.\n",
      "#Person1#: What about the expression'goodbye '? Is that an idiom?\n",
      "#Person2#: That is just a natural, grammatical English expression. It has a direct translation in other languages.\n",
      "#Person1#: This is interesting, Ms. Parker.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "torch.Size([6, 360])\n",
      "index:  0\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  1\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "index:  2\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  3\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "index:  4\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  5\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "torch.Size([6, 56])\n",
      "index:  0\n",
      "#Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.\n",
      "index:  1\n",
      "Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.\n",
      "index:  2\n",
      "#Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.\n",
      "index:  3\n",
      "Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.\n",
      "index:  4\n",
      "#Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.\n",
      "index:  5\n",
      "Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.\n",
      "torch.Size([6, 56])\n",
      "index:  0\n",
      "</s><s>#Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.\n",
      "index:  1\n",
      "</s><s>Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  2\n",
      "</s><s>#Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.\n",
      "index:  3\n",
      "</s><s>Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  4\n",
      "</s><s>#Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.\n",
      "index:  5\n",
      "</s><s>Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "torch.Size([6, 232])\n",
      "index:  0\n",
      "<s>Topic of Summary: pleasant meal. Length of Summary: 20. Dialogue: #Person1#: Did you enjoy your meal?\n",
      "#Person2#: Yes, we really enjoyed it.\n",
      "#Person1#: May I interest you in some dessert?\n",
      "#Person2#: Yes, that sounds great.\n",
      "#Person1#: Well, we have chocolate mousse cake, homemade fresh strawberry shortcake, and a spicy rum apple crisp for our specials.\n",
      "#Person2#: The apple crisp sounds great.\n",
      "#Person1#: Since there are four of you, would you like to split a second dessert?\n",
      "#Person2#: Good suggestion. Could you please bring us a chocolate mousse cake and four dessert forks, please?\n",
      "#Person1#: Would you like coffee or tea with your dessert?\n",
      "#Person2#: Let's have four coffees, please.\n",
      "#Person1#: OK. I will be right back with your desserts and drinks.\n",
      "#Person2#: Thank you! We have really enjoyed our meal here.</s><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  1\n",
      "<s>Topic of Summary: country. Length of Summary: 12. Dialogue: #Person1#: The country is strong only in appearance. Don't you think so? \n",
      "#Person2#: Yes. In fact there are quite a large number of people who have no food to eat and no place to live in. \n",
      "#Person1#: You can say that again. The government must open it's eyes to the fact. </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  2\n",
      "<s>Topic of Summary: dessert forks. Length of Summary: 20. Dialogue: #Person1#: Did you enjoy your meal?\n",
      "#Person2#: Yes, we really enjoyed it.\n",
      "#Person1#: May I interest you in some dessert?\n",
      "#Person2#: Yes, that sounds great.\n",
      "#Person1#: Well, we have chocolate mousse cake, homemade fresh strawberry shortcake, and a spicy rum apple crisp for our specials.\n",
      "#Person2#: The apple crisp sounds great.\n",
      "#Person1#: Since there are four of you, would you like to split a second dessert?\n",
      "#Person2#: Good suggestion. Could you please bring us a chocolate mousse cake and four dessert forks, please?\n",
      "#Person1#: Would you like coffee or tea with your dessert?\n",
      "#Person2#: Let's have four coffees, please.\n",
      "#Person1#: OK. I will be right back with your desserts and drinks.\n",
      "#Person2#: Thank you! We have really enjoyed our meal here.</s><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  3\n",
      "<s>Topic of Summary: people. Length of Summary: 12. Dialogue: #Person1#: The country is strong only in appearance. Don't you think so? \n",
      "#Person2#: Yes. In fact there are quite a large number of people who have no food to eat and no place to live in. \n",
      "#Person1#: You can say that again. The government must open it's eyes to the fact. </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  4\n",
      "<s>Topic of Summary: cooking show. Length of Summary: 20. Dialogue: #Person1#: Did you enjoy your meal?\n",
      "#Person2#: Yes, we really enjoyed it.\n",
      "#Person1#: May I interest you in some dessert?\n",
      "#Person2#: Yes, that sounds great.\n",
      "#Person1#: Well, we have chocolate mousse cake, homemade fresh strawberry shortcake, and a spicy rum apple crisp for our specials.\n",
      "#Person2#: The apple crisp sounds great.\n",
      "#Person1#: Since there are four of you, would you like to split a second dessert?\n",
      "#Person2#: Good suggestion. Could you please bring us a chocolate mousse cake and four dessert forks, please?\n",
      "#Person1#: Would you like coffee or tea with your dessert?\n",
      "#Person2#: Let's have four coffees, please.\n",
      "#Person1#: OK. I will be right back with your desserts and drinks.\n",
      "#Person2#: Thank you! We have really enjoyed our meal here.</s><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  5\n",
      "<s>Topic of Summary: celebrate birthday. Length of Summary: 12. Dialogue: #Person1#: The country is strong only in appearance. Don't you think so? \n",
      "#Person2#: Yes. In fact there are quite a large number of people who have no food to eat and no place to live in. \n",
      "#Person1#: You can say that again. The government must open it's eyes to the fact. </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "torch.Size([6, 232])\n",
      "index:  0\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s>\n",
      "index:  1\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "index:  2\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s>\n",
      "index:  3\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "index:  4\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s>\n",
      "index:  5\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "torch.Size([6, 40])\n",
      "index:  0\n",
      "#Person2# quite enjoys the meal and #Person1# will serve #Person2# an apple crisp, a chocolate mousse cake, and four coffees.\n",
      "index:  1\n",
      "#Person1# and #Person2# agree that this country is strong only in appearance.\n",
      "index:  2\n",
      "#Person2# quite enjoys the meal and #Person1# will serve #Person2# an apple crisp, a chocolate mousse cake, and four coffees.\n",
      "index:  3\n",
      "#Person1# and #Person2# agree that this country is strong only in appearance.\n",
      "index:  4\n",
      "#Person2# quite enjoys the meal and #Person1# will serve #Person2# an apple crisp, a chocolate mousse cake, and four coffees.\n",
      "index:  5\n",
      "#Person1# and #Person2# agree that this country is strong only in appearance.\n",
      "torch.Size([6, 40])\n",
      "index:  0\n",
      "</s><s>#Person2# quite enjoys the meal and #Person1# will serve #Person2# an apple crisp, a chocolate mousse cake, and four coffees.</s><pad><pad><pad>\n",
      "index:  1\n",
      "</s><s>#Person1# and #Person2# agree that this country is strong only in appearance.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  2\n",
      "</s><s>#Person2# quite enjoys the meal and #Person1# will serve #Person2# an apple crisp, a chocolate mousse cake, and four coffees.</s><pad><pad><pad>\n",
      "index:  3\n",
      "</s><s>#Person1# and #Person2# agree that this country is strong only in appearance.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "index:  4\n",
      "</s><s>#Person2# quite enjoys the meal and #Person1# will serve #Person2# an apple crisp, a chocolate mousse cake, and four coffees.</s><pad><pad><pad>\n",
      "index:  5\n",
      "</s><s>#Person1# and #Person2# agree that this country is strong only in appearance.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    for ind, batch_keys in enumerate(batch.keys()):\n",
    "        print(batch[batch_keys].shape)\n",
    "        for indx in range(batch[batch_keys].shape[0]):\n",
    "            print(\"index: \", indx)\n",
    "            if batch_keys == 'labels':\n",
    "                batch[batch_keys][indx] = torch.where(batch[batch_keys][indx] != -100, batch[batch_keys][indx], tokenizer.pad_token_id)\n",
    "                print(tokenizer.decode((batch[batch_keys][indx]), skip_special_tokens=True))\n",
    "            else:\n",
    "                print(tokenizer.decode((batch[batch_keys][indx])))\n",
    "                # print(tokenizer.decode((batch[batch_keys][indx]), skip_special_tokens=True))\n",
    "    if step == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
      "torch.Size([8, 448])\n",
      "torch.Size([8, 448])\n",
      "torch.Size([8, 72])\n",
      "torch.Size([8, 72])\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(test_dataloader):\n",
    "    print(batch.keys())\n",
    "    print(batch['input_ids'].shape)\n",
    "    print(batch['attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    print(batch['decoder_input_ids'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 48])\n",
      "torch.Size([8, 48])\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(eval_dataloader):\n",
    "    print(batch.keys())\n",
    "    print(batch['input_ids'].shape)\n",
    "    print(batch['attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    print(batch['decoder_input_ids'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing DataLoader Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3z17N4Jsu3Y",
    "outputId": "1849c4bf-2915-4771-b728-98c0e23ab664",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "04/14/2024 08:32:19 - INFO - __main__ - ***** Running training *****\n",
      "04/14/2024 08:32:19 - INFO - __main__ -  Num examples = 1500\n",
      "04/14/2024 08:32:19 - INFO - __main__ -  Num Epochs = 1\n",
      "04/14/2024 08:32:19 - INFO - __main__ -  Instantaneous batch size per device = 2\n",
      "04/14/2024 08:32:19 - INFO - __main__ -  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "04/14/2024 08:32:19 - INFO - __main__ -  Gradient Accumulation steps = 32\n",
      "04/14/2024 08:32:19 - INFO - __main__ -  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a019e43dd0c47819e8ab4fdaebab74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# = = = Training Preparation = = =\n",
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "if args.ctrlen_model: \n",
    "    no_decay_emb_matrix = [\"bias\", \"LayerNorm.weight\", \"shared\"]\n",
    "else:\n",
    "    no_decay_emb_matrix = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay_emb_matrix)],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "if args.ctrlen_model:\n",
    "    if args.model_type == 'bart': \n",
    "        optimizer_grouped_parameters.extend([{\n",
    "            \"params\": model.seq2seq_model.model.shared.parameters(),\n",
    "            \"lr\": args.embedding_lr}])\n",
    "    elif args.model_type == 't5':\n",
    "        optimizer_grouped_parameters.extend([{\n",
    "            \"params\": model.seq2seq_model.shared.parameters(),\n",
    "            \"lr\": args.embedding_lr}])\n",
    "    else:\n",
    "        raise ValueError('{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "# optimizer\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\n",
    "model, optimizer, train_dataloader, eval_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader, test_dataloader\n",
    ")\n",
    "\n",
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
    "if args.max_train_steps is None:\n",
    "    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
    "else:\n",
    "    args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=args.lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.num_warmup_steps,\n",
    "    num_training_steps=args.max_train_steps,\n",
    ")\n",
    "\n",
    "# = = = = = = = = = = = = = = = = Train = = = = = = = = = = = = = = = = = = =\n",
    "total_batch_size = (\n",
    "    args.per_device_train_batch_size\n",
    "    * accelerator.num_processes\n",
    "    * args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\" Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\" Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(\n",
    "    f\" Instantaneous batch size per device = {args.per_device_train_batch_size}\"\n",
    ")\n",
    "logger.info(\n",
    "    f\" Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\"\n",
    ")\n",
    "logger.info(f\" Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\" Total optimization steps = {args.max_train_steps}\")\n",
    "\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(\n",
    "    range(args.max_train_steps),\n",
    "    desc=\"Training: \",\n",
    "    disable=not accelerator.is_local_main_process,\n",
    ")\n",
    "completed_steps = 0\n",
    "\n",
    "val_results = []\n",
    "acc_losses = []\n",
    "losses_all = []\n",
    "losses_steps = []\n",
    "losses_epoch = []\n",
    "contrastive_losses_all_top = []\n",
    "contrastive_losses_steps_top = []\n",
    "contrastive_losses_epoch_top = []\n",
    "contrastive_losses_all_tail = []\n",
    "contrastive_losses_steps_tail = []\n",
    "contrastive_losses_epoch_tail = []\n",
    "contrastive_losses_all_top_tail = []\n",
    "contrastive_losses_steps_top_tail = []\n",
    "contrastive_losses_epoch_top_tail = []\n",
    "best_r2_f1 = None\n",
    "best_epoch = 0\n",
    "\n",
    "if args.model_type == \"bart\" or args.model_type == \"t5\":\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get(\"summarization\", {})\n",
    "    params[\"min_length\"] = args.min_target_length\n",
    "    params[\"max_length\"] = args.max_target_length\n",
    "    params[\"length_penalty\"] = args.length_penalty\n",
    "    params[\"num_beams\"] = args.num_beams\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError(\"{} model type not implemented\".format(args.model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_cs_top  margin 0.4:  tensor(0.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.1906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.1972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.1934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.1974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.1590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.3777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.2494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.5377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.0383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.3325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss_cs_top  margin 0.4:  tensor(0.3983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs_tail margin 0.1:  tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss_cs:  tensor(0.5394, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = Train =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    loss_epoch = []\n",
    "    loss_steps = []\n",
    "    contrastive_epoch_top = []\n",
    "    contrastive_epoch_tail = []\n",
    "    contrastive_epoch_top_tail = []\n",
    "    contrastive_steps_top = []\n",
    "    contrastive_steps_tail = []\n",
    "    contrastive_steps_top_tail = []\n",
    "    # train\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if args.ctrlen_model:  # CTRLen model\n",
    "            outputs, loss = model(batch, tokenizer)\n",
    "        # w/ and w/o label smoothing (always better with label smoothing)\n",
    "        else:\n",
    "            if args.label_smoothing == 0:\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "            else:\n",
    "                outputs = model(**batch)\n",
    "                output_logits = outputs.logits\n",
    "                output_probs = torch.nn.functional.log_softmax(\n",
    "                    output_logits, dim=-1\n",
    "                )\n",
    "\n",
    "                if args.contrastive != \"no\":\n",
    "                    max_encoder_token = model.config.max_position_embeddings\n",
    "                    embeddings = outputs.encoder_last_hidden_state[\n",
    "                        : args.per_device_train_batch_size, :, :max_encoder_token\n",
    "                    ]\n",
    "                    embeddings = embeddings.reshape(-1, max_encoder_token)\n",
    "                    minus_one = -torch.ones(embeddings.size(dim=0)).to(device)\n",
    "\n",
    "                    # =====================================================#\n",
    "                    # differrent margin\n",
    "                    embeddings_for_top = embeddings\n",
    "                    embeddings_for_tail = embeddings\n",
    "                    # =====================================================#\n",
    "\n",
    "                    # if args.contrastive == \"top-tail\":\n",
    "                    #     embeddings = torch.cat((embeddings, embeddings), 0)\n",
    "                    #     minus_one = torch.cat((minus_one, minus_one), 0)\n",
    "\n",
    "                    pair_embeddings = outputs.encoder_last_hidden_state[\n",
    "                        args.per_device_train_batch_size :, :, :max_encoder_token\n",
    "                    ]\n",
    "                    pair_embeddings = pair_embeddings.reshape(-1, max_encoder_token)\n",
    "\n",
    "                    # =====================================================#\n",
    "                    # differrent margin\n",
    "                    pair_embeddings_top = pair_embeddings[:embeddings.shape[0]]\n",
    "                    pair_embeddings_tail = pair_embeddings[embeddings.shape[0]:]\n",
    "                    # =====================================================#\n",
    "\n",
    "                    # print(\"embeddings top shape: \", embeddings.shape)\n",
    "                    # print(\"pair_embeddings top shape: \", pair_embeddings_top.shape)\n",
    "                    # print(\"embeddings tail shape: \", embeddings.shape)\n",
    "                    # print(\"pair_embeddings tail shape: \", pair_embeddings_tail.shape)\n",
    "                    # print(\"minus_one: \", minus_one.shape)\n",
    "                    \n",
    "                    # loss_cs = cosine_embedding_loss(\n",
    "                    #     embeddings, pair_embeddings, minus_one, args.margin\n",
    "                    # )\n",
    "\n",
    "                    # =====================================================#\n",
    "                    # differrent margin\n",
    "                    loss_cs_top = cosine_embedding_loss(\n",
    "                        embeddings_for_top, pair_embeddings_top, minus_one, 0.4\n",
    "                    )\n",
    "                    loss_cs_tail = cosine_embedding_loss(\n",
    "                        embeddings_for_tail, pair_embeddings_tail, minus_one, 0.1\n",
    "                    )\n",
    "                    loss_cs = (loss_cs_top + loss_cs_tail) / 2\n",
    "                    # =====================================================#\n",
    "\n",
    "                    print(\"loss_cs_top  margin 0.4: \", loss_cs_top)\n",
    "                    print(\"loss_cs_tail margin 0.1: \", loss_cs_tail)\n",
    "                    print(\"loss_cs: \", loss_cs)\n",
    "\n",
    "                    # break\n",
    "\n",
    "                    output_probs = output_probs[\n",
    "                        : args.per_device_train_batch_size, :, :\n",
    "                    ]\n",
    "                    output_probs = output_probs.view(-1, model.config.vocab_size)\n",
    "                    gt_logits = batch[\"labels\"][\n",
    "                        : args.per_device_train_batch_size, :\n",
    "                    ]\n",
    "                    gt_logits = gt_logits.view(-1)\n",
    "                    loss_nll, _ = label_smoothed_nll_loss(\n",
    "                        output_probs,\n",
    "                        gt_logits,\n",
    "                        args.label_smoothing,\n",
    "                        ignore_index=tokenizer.pad_token_id,\n",
    "                    )\n",
    "                    # joint loss\n",
    "                    loss = loss_nll + (args.alpha * loss_cs)\n",
    "\n",
    "                else:\n",
    "                    output_probs = output_probs.view(-1, model.config.vocab_size)\n",
    "\n",
    "                    gt_logits = batch[\"labels\"]\n",
    "                    gt_logits = gt_logits.view(-1)\n",
    "\n",
    "                    loss, _ = label_smoothed_nll_loss(\n",
    "                        output_probs,\n",
    "                        gt_logits,\n",
    "                        args.label_smoothing,\n",
    "                        ignore_index=tokenizer.pad_token_id,\n",
    "                    )\n",
    "\n",
    "        losses_all.append(loss.item())\n",
    "\n",
    "        loss_epoch.append(loss.item())\n",
    "        loss_steps.append(loss.item())           \n",
    "        \n",
    "        acc_losses.append(loss.item())\n",
    "        loss = loss / args.gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        contrastive_losses_all_top.append(loss_cs_top.item())\n",
    "        contrastive_losses_all_tail.append(loss_cs_tail.item())\n",
    "        contrastive_losses_all_top_tail.append(loss_cs.item())\n",
    "\n",
    "        contrastive_steps_top.append(loss_cs_top.item())\n",
    "        contrastive_steps_tail.append(loss_cs_tail.item())\n",
    "        contrastive_steps_top_tail.append(loss_cs.item())\n",
    "\n",
    "        contrastive_epoch_top.append(loss_cs_top.item())\n",
    "        contrastive_epoch_tail.append(loss_cs_tail.item())\n",
    "        contrastive_epoch_top_tail.append(loss_cs.item())\n",
    "\n",
    "        if (\n",
    "            step % args.gradient_accumulation_steps == 0\n",
    "            or step == len(train_dataloader) - 1\n",
    "        ):\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix(\n",
    "                lr=lr_scheduler.get_last_lr()[0], loss=np.mean(acc_losses[-50:])\n",
    "            )\n",
    "            completed_steps += 1\n",
    "\n",
    "            losses_steps.append(np.mean(loss_steps))\n",
    "            contrastive_losses_steps_top.append(np.mean(contrastive_steps_top))\n",
    "            contrastive_losses_steps_top.append(np.mean(contrastive_steps_tail))\n",
    "            contrastive_losses_steps_top.append(np.mean(contrastive_steps_top_tail))\n",
    "\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "            break\n",
    "             \n",
    "    losses_epoch.append(np.mean(loss_epoch))\n",
    "    contrastive_losses_epoch_top.append(np.mean(contrastive_epoch_top))\n",
    "    contrastive_losses_epoch_tail.append(np.mean(contrastive_epoch_tail))\n",
    "    contrastive_losses_epoch_top_tail.append(np.mean(contrastive_epoch_top_tail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "04/14/2024 08:33:29 - INFO - __main__ - \n",
      "04/14/2024 08:33:29 - INFO - __main__ - Rouge score on val set after epoch 1\n",
      "04/14/2024 08:33:29 - INFO - root - \n",
      "04/14/2024 08:33:29 - INFO - root - \trouge-1:\tP: 50.31\tR: 43.34\tF1: 44.93\n",
      "04/14/2024 08:33:29 - INFO - root - \trouge-2:\tP: 22.85\tR: 19.38\tF1: 20.13\n",
      "04/14/2024 08:33:29 - INFO - root - \trouge-l:\tP: 51.40\tR: 45.46\tF1: 47.04\n",
      "04/14/2024 08:33:29 - INFO - root - \n",
      "Configuration saved in ./output/0/best/config.json\n",
      "Configuration saved in ./output/0/best/generation_config.json\n",
      "Model weights saved in ./output/0/best/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/0/best/tokenizer_config.json\n",
      "Special tokens file saved in ./output/0/best/special_tokens_map.json\n",
      "04/14/2024 08:33:44 - INFO - __main__ - Current Best Validation Result is at epoch 1\n",
      "04/14/2024 08:33:44 - INFO - root - \n",
      "04/14/2024 08:33:44 - INFO - root - \trouge-1:\tP: 50.31\tR: 43.34\tF1: 44.93\n",
      "04/14/2024 08:33:44 - INFO - root - \trouge-2:\tP: 22.85\tR: 19.38\tF1: 20.13\n",
      "04/14/2024 08:33:44 - INFO - root - \trouge-l:\tP: 51.40\tR: 45.46\tF1: 47.04\n",
      "04/14/2024 08:33:44 - INFO - root - \n"
     ]
    }
   ],
   "source": [
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = EVAL =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "model.eval()\n",
    "val_predict = []\n",
    "val_groundtruth = []\n",
    "for step, batch in enumerate(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "            batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n",
    "        )\n",
    "\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = batch[\"labels\"]\n",
    "        if not args.pad_to_max_length:\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "        generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "        labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "        if args.ignore_pad_token_for_loss:\n",
    "            # Replace -100 in the labels as we can't decode them.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(\n",
    "            generated_tokens, skip_special_tokens=True\n",
    "        )\n",
    "        decoded_labels = tokenizer.batch_decode(\n",
    "            labels, skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        decoded_preds, decoded_labels = postprocess_text(\n",
    "            decoded_preds, decoded_labels\n",
    "        )\n",
    "\n",
    "        val_predict.extend(decoded_preds)\n",
    "        val_groundtruth.extend(decoded_labels)\n",
    "\n",
    "if args.len_output == \"real\":\n",
    "    new_val_predict = []\n",
    "    for sample in val_predict:\n",
    "        try:\n",
    "            gen_sum = sample.split(\"Summary: \")[2]\n",
    "            new_val_predict.append(gen_sum)\n",
    "        except:\n",
    "            new_val_predict.append(sample)\n",
    "    val_predict = new_val_predict\n",
    "else:\n",
    "    new_val_predict = val_predict\n",
    "\n",
    "logger.info(\"\")\n",
    "logger.info(\"Rouge score on val set after epoch {}\".format(epoch + 1))\n",
    "eval_results = py_rouge_scores(val_predict, val_groundtruth)\n",
    "\n",
    "if best_r2_f1 is None:\n",
    "    best_r2_f1 = eval_results\n",
    "if eval_results[\"rouge-2\"][\"f\"] >= best_r2_f1[\"rouge-2\"][\"f\"]:\n",
    "    best_r2_f1 = eval_results\n",
    "    best_epoch = epoch + 1\n",
    "\n",
    "    os.makedirs(args.output_dir + \"/best\", exist_ok=True)\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(\n",
    "        args.output_dir + \"/best\", save_function=accelerator.save\n",
    "    )\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(args.output_dir + \"/best\")\n",
    "\n",
    "    # save vocab\n",
    "    vocab = tokenizer.vocab.copy()\n",
    "    vocab = {k: v for k, v in sorted(vocab.items(), key=lambda item: item[1])}\n",
    "    with open(args.output_dir + \"/best/vocab.txt\", \"w\") as f:\n",
    "        for word, index in vocab.items():\n",
    "            # it lead to encoding bug on some machines, so i add this line\n",
    "            word = word.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "            f.write(str(index) + \": \" + word + \"\\n\")\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "logger.info(\"Current Best Validation Result is at epoch {}\".format(best_epoch))\n",
    "py_rouge_scores(None, None, best_r2_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_json_loss = f'{args.output_dir}/loss_{args.len_input}_{args.contrastive}.json'\n",
    "file_json_contrastive = f'{args.output_dir}/contrastive_{args.len_input}_{args.contrastive}.json'\n",
    "\n",
    "loss_json = {\n",
    "    \"losses_steps\": losses_steps,\n",
    "    \"losses_epoch\": losses_epoch,\n",
    "    \"losses_all\": losses_all\n",
    "}\n",
    "\n",
    "contrastive_json = {\n",
    "    \"contrastive_losses_steps_top\": contrastive_losses_steps_top,\n",
    "    \"contrastive_losses_epoch_top\": contrastive_losses_epoch_top,\n",
    "    \"contrastive_losses_all_top\": contrastive_losses_all_top,\n",
    "    \"contrastive_losses_steps_tail\": contrastive_losses_steps_tail,\n",
    "    \"contrastive_losses_epoch_tail\": contrastive_losses_epoch_tail,\n",
    "    \"contrastive_losses_all_tail\": contrastive_losses_all_tail,\n",
    "    \"contrastive_losses_steps_top_tail\": contrastive_losses_steps_top_tail,\n",
    "    \"contrastive_losses_epoch_top_tail\": contrastive_losses_epoch_top_tail,\n",
    "    \"contrastive_losses_all_top_tail\": contrastive_losses_all_top_tail,\n",
    "}\n",
    "\n",
    "with open(file_json_loss, 'w') as output_file:\n",
    "    print(json.dumps(loss_json), file=output_file)\n",
    "\n",
    "with open(file_json_contrastive, 'w') as output_file:\n",
    "    print(json.dumps(contrastive_json), file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13bb8c4b9a154bb99c4d38cd2edb631c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14052c5abfad4231a0d4c8d0e0395a01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24272444846441638d4836fd835562dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f6c1bca77640ca92bd87d5995fced5",
       "IPY_MODEL_81669ba2443a489cb535c508333dc974",
       "IPY_MODEL_47ddb2c2d8fa4c278c9d514ace68341f"
      ],
      "layout": "IPY_MODEL_b842e08bc1ca45ee99a868d1dfa4d0db"
     }
    },
    "31409e259c8b4ee7899035ea4ba3f140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "326356876bd540778d188c41673e04f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35f50d433dc14aa28cf0f5a039f7cb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "368a820467ad4f4d8198932125f0d357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bad8094e9124ab391d945edf4ccca2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4616558f0ebd466babad0202bc55824d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47ddb2c2d8fa4c278c9d514ace68341f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_932e4629e7f340c2a5b64d095c46bf4d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a26c7dc74d71494787fd32d560594b38",
      "value": " 500/500 [00:01&lt;00:00, 317.13 examples/s]"
     }
    },
    "542a00a050384f5f8f3f7354eb527336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2947306125452c8c25c12e54dc6656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78f6c1bca77640ca92bd87d5995fced5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4616558f0ebd466babad0202bc55824d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9a4ed651601f4a29b763eed10afafc16",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "7f1272db213a4121ae95b5e41061d964": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e69f5057741b46dba3ebb186ef85c6db",
      "max": 1500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14052c5abfad4231a0d4c8d0e0395a01",
      "value": 1500
     }
    },
    "81669ba2443a489cb535c508333dc974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_368a820467ad4f4d8198932125f0d357",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5ece15e08e44905a09d9a2e988a4be4",
      "value": 500
     }
    },
    "852ba2b2a4fd4bbe80a2ecd9c9f6b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1a15a93c5e746888806f8dd19cf6889",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_35f50d433dc14aa28cf0f5a039f7cb87",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "90b25ecb208546f9938652c360ef7a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_852ba2b2a4fd4bbe80a2ecd9c9f6b5fb",
       "IPY_MODEL_7f1272db213a4121ae95b5e41061d964",
       "IPY_MODEL_a3ad3e93702041d89b6f505ec6d37411"
      ],
      "layout": "IPY_MODEL_ffcb842d99954cdcaa8fb78e8e3b2215"
     }
    },
    "932e4629e7f340c2a5b64d095c46bf4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a4ed651601f4a29b763eed10afafc16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c182b108efa471994186923f10871a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a26c7dc74d71494787fd32d560594b38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3ad3e93702041d89b6f505ec6d37411": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bad8094e9124ab391d945edf4ccca2f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_31409e259c8b4ee7899035ea4ba3f140",
      "value": " 1500/1500 [00:03&lt;00:00, 414.56 examples/s]"
     }
    },
    "a91a8c5870234ab3bdd0132addb34a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1a15a93c5e746888806f8dd19cf6889": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b842e08bc1ca45ee99a868d1dfa4d0db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c34934bec45646a8b2ac76c60dc124d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0098c03b82d48c9acdc684fbbf54567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa32d34f467944f2aaf4a13fdf7a0cf2",
       "IPY_MODEL_e3bc145889c94fc3974e88e46863db89",
       "IPY_MODEL_ddbc6421b4cf487d92cc53fb0ae6f634"
      ],
      "layout": "IPY_MODEL_13bb8c4b9a154bb99c4d38cd2edb631c"
     }
    },
    "ddbc6421b4cf487d92cc53fb0ae6f634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c182b108efa471994186923f10871a8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c34934bec45646a8b2ac76c60dc124d5",
      "value": " 12460/12460 [00:20&lt;00:00, 564.66 examples/s]"
     }
    },
    "e3bc145889c94fc3974e88e46863db89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_542a00a050384f5f8f3f7354eb527336",
      "max": 12460,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a91a8c5870234ab3bdd0132addb34a20",
      "value": 12460
     }
    },
    "e69f5057741b46dba3ebb186ef85c6db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5ece15e08e44905a09d9a2e988a4be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa32d34f467944f2aaf4a13fdf7a0cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a2947306125452c8c25c12e54dc6656",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_326356876bd540778d188c41673e04f5",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "ffcb842d99954cdcaa8fb78e8e3b2215": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
