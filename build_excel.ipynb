{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "062780dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import difflib\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from rouge_s import py_rouge_scores\n",
    "from bert_score import score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "329f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_method = {'1': '1_bart_noprompt', '2': '2_bart_topic', '3': '3_bart_length', \n",
    "               '4': '4_bart_topic_length', '5': '5_bart_contrastive_random', '6': '6_bart_contrastive_synonym',\n",
    "               '7': '7_bart_contrastive_combine', '8': '8_bart_contrastive_combine_word_tagger', '9': '9_bart-contrastive-combine-prompt-tagger'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7db8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_method = 9\n",
    "\n",
    "list_method = list(range(1 ,total_method + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ef5c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gold_summary(file_path):\n",
    "    \"\"\"load result jsonl data\"\"\"\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    id_list = [sample[\"fname\"] for sample in data]\n",
    "    dialogue_list = [sample[\"dialogue\"] for sample in data]\n",
    "\n",
    "    summary_list1 = [sample[\"summary1\"] for sample in data]\n",
    "    summary_list2 = [sample[\"summary2\"] for sample in data]\n",
    "    summary_list3 = [sample[\"summary3\"] for sample in data]\n",
    "    \n",
    "    topic_list1 = [sample[\"topic1\"] for sample in data]\n",
    "    topic_list2 = [sample[\"topic2\"] for sample in data]\n",
    "    topic_list3 = [sample[\"topic3\"] for sample in data]\n",
    "\n",
    "    data_dict = {\n",
    "    \"fname\": id_list,\n",
    "    \"dialogue\": dialogue_list,\n",
    "    \"summary1\": summary_list1,\n",
    "    \"summary1\": summary_list1,\n",
    "    \"summary2\": summary_list2,\n",
    "    \"summary3\": summary_list3,\n",
    "    \"topic1\": topic_list1,\n",
    "    \"topic2\": topic_list2,\n",
    "    \"topic3\": topic_list3,\n",
    "    }\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58c2bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(file_path):\n",
    "    \"\"\"load result jsonl data\"\"\"\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    id_list = [sample[\"fname\"] for sample in data]\n",
    "\n",
    "    summary_list1 = [sample[\"gen_summary1\"] for sample in data]\n",
    "    summary_list2 = [sample[\"gen_summary2\"] for sample in data]\n",
    "    summary_list3 = [sample[\"gen_summary3\"] for sample in data]\n",
    "\n",
    "    data_dict = {\n",
    "    \"fname\": id_list,\n",
    "    \"gen_summary1\": summary_list1,\n",
    "    \"gen_summary2\": summary_list2,\n",
    "    \"gen_summary3\": summary_list3,\n",
    "    }\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "357f96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_summary = load_gold_summary(f\"./data/dialogsum/dialogsum.test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a869469",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_summary_df = pd.DataFrame.from_dict(gold_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e342c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary1</th>\n",
       "      <th>summary2</th>\n",
       "      <th>summary3</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>communication method</td>\n",
       "      <td>company policy</td>\n",
       "      <td>dictation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#: You're finally here! What took so l...</td>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
       "      <td>public transportation</td>\n",
       "      <td>transportation</td>\n",
       "      <td>discuss transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#: Kate, you never believe what's happ...</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
       "      <td>divorce</td>\n",
       "      <td>divorce</td>\n",
       "      <td>discuss divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#: Happy Birthday, this is for you, Br...</td>\n",
       "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
       "      <td>#Person1# attends Brian's birthday party. Bria...</td>\n",
       "      <td>#Person1# has a dance with Brian at Brian's bi...</td>\n",
       "      <td>birthday party</td>\n",
       "      <td>birthday party</td>\n",
       "      <td>birthday party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#: This Olympic park is so big!\\n#Pers...</td>\n",
       "      <td>#Person1# is surprised at the Olympic Stadium'...</td>\n",
       "      <td>#Person2# shows #Person1# around the construct...</td>\n",
       "      <td>#Person2# introduces the Olympic Stadium's fin...</td>\n",
       "      <td>Olympic Stadium</td>\n",
       "      <td>sports stadium</td>\n",
       "      <td>Olympic Stadium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fname                                           dialogue  \\\n",
       "0  test_0  #Person1#: Ms. Dawson, I need you to take a di...   \n",
       "1  test_1  #Person1#: You're finally here! What took so l...   \n",
       "2  test_2  #Person1#: Kate, you never believe what's happ...   \n",
       "3  test_3  #Person1#: Happy Birthday, this is for you, Br...   \n",
       "4  test_4  #Person1#: This Olympic park is so big!\\n#Pers...   \n",
       "\n",
       "                                            summary1  \\\n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1  #Person2# arrives late because of traffic jam....   \n",
       "2  #Person1# tells Kate that Masha and Hero get d...   \n",
       "3  #Person1# and Brian are at the birthday party ...   \n",
       "4  #Person1# is surprised at the Olympic Stadium'...   \n",
       "\n",
       "                                            summary2  \\\n",
       "0  In order to prevent employees from wasting tim...   \n",
       "1  #Person2# decides to follow #Person1#'s sugges...   \n",
       "2  #Person1# tells Kate that Masha and Hero are g...   \n",
       "3  #Person1# attends Brian's birthday party. Bria...   \n",
       "4  #Person2# shows #Person1# around the construct...   \n",
       "\n",
       "                                            summary3                 topic1  \\\n",
       "0  Ms. Dawson takes a dictation for #Person1# abo...   communication method   \n",
       "1  #Person2# complains to #Person1# about the tra...  public transportation   \n",
       "2  #Person1# and Kate talk about the divorce betw...                divorce   \n",
       "3  #Person1# has a dance with Brian at Brian's bi...         birthday party   \n",
       "4  #Person2# introduces the Olympic Stadium's fin...        Olympic Stadium   \n",
       "\n",
       "           topic2                  topic3  \n",
       "0  company policy               dictation  \n",
       "1  transportation  discuss transportation  \n",
       "2         divorce         discuss divorce  \n",
       "3  birthday party          birthday party  \n",
       "4  sports stadium         Olympic Stadium  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9a0f655-7a2d-4371-be5c-afdd3bcef366",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_summary_df.to_excel(\"dataset.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc883800",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all_df = {}\n",
    "for i in list_method:\n",
    "    result_dict = load_result(f\"./result/{i}.jsonl\")\n",
    "    result_df = pd.DataFrame.from_dict(result_dict)\n",
    "    result_all_df[i] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc9437b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>gen_summary1</th>\n",
       "      <th>gen_summary2</th>\n",
       "      <th>gen_summary3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
       "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
       "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1# celebrates Brian's birthday and danc...</td>\n",
       "      <td>#Person1# celebrates Brian's birthday and danc...</td>\n",
       "      <td>#Person1# celebrates Brian's birthday and danc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1# and #Person2# are in the Olympic sta...</td>\n",
       "      <td>#Person1# and #Person2# are in the Olympic sta...</td>\n",
       "      <td>#Person1# and #Person2# are in the Olympic sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fname                                       gen_summary1  \\\n",
       "0  test_0  #Person1# asks Ms. Dawson to take a dictation ...   \n",
       "1  test_1  #Person2# got stuck in traffic again. #Person1...   \n",
       "2  test_2  #Person1# tells Kate that Masha and Hero are g...   \n",
       "3  test_3  #Person1# celebrates Brian's birthday and danc...   \n",
       "4  test_4  #Person1# and #Person2# are in the Olympic sta...   \n",
       "\n",
       "                                        gen_summary2  \\\n",
       "0  #Person1# asks Ms. Dawson to take a dictation ...   \n",
       "1  #Person2# got stuck in traffic again. #Person1...   \n",
       "2  #Person1# tells Kate that Masha and Hero are g...   \n",
       "3  #Person1# celebrates Brian's birthday and danc...   \n",
       "4  #Person1# and #Person2# are in the Olympic sta...   \n",
       "\n",
       "                                        gen_summary3  \n",
       "0  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "1  #Person2# got stuck in traffic again. #Person1...  \n",
       "2  #Person1# tells Kate that Masha and Hero are g...  \n",
       "3  #Person1# celebrates Brian's birthday and danc...  \n",
       "4  #Person1# and #Person2# are in the Olympic sta...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_all_df[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28996fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_method = 1\n",
    "\n",
    "num_example = 1\n",
    "gen_summary_num = 0\n",
    "\n",
    "list_gold_summary = ['summary1', 'summary2', 'summary3']\n",
    "list_gold_topic = ['topic1', 'topic2', 'topic3']\n",
    "list_gen_summary = ['gen_summary1', 'gen_summary2', 'gen_summary3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "647aa7ea-c98a-405a-b272-9e3008b6980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a15f43bc7439aa32f89466e6b702b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b63b7343dd04240a084a8f1c988f239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.53 seconds, 327.32 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ae6195832f41d988f06d7936dec0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b5a4bb6e0e44458329d8550a8bb807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.52 seconds, 329.33 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3899d5c9e2543738bce195ddd8e850d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce95681f4ed45c8827b3f15eee86121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.50 seconds, 334.00 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3c4d0177864827bc988d358b201173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f78f9418c404b90826fe747eb6efe2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.50 seconds, 332.47 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16516a8337ed4444bea46f709e442e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ebb361169f4279b96c03e05b4d80df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.49 seconds, 336.16 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7531b7b67c914e24865cebd578a3016a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e771c0cf6241bcbce3e27d53083a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.50 seconds, 334.26 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02e95e7cbf847748a547bb1ee5c0db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8721da97aa564e5093595548a4da9cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.46 seconds, 342.93 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74068bf2530044c78a296f5a6844499b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3c9d3a0bff4cea8ff68f3091685bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.44 seconds, 348.01 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a66df86af334effb0b3cdf649c3af85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66005995e94846718c776bedaec82bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.44 seconds, 347.97 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e784bb6b145e18efd8d69ca1b6def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2403828ae874025a9cef6da289a8cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.59 seconds, 192.85 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0da8863dd04d789b46630d5e0703ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0f65d51c9d401ba5818275b1fc6bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.60 seconds, 192.67 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5586f3aeb9c7454b8e3085f490dcf411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaed8404f064ad4965f421a185be5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.77 seconds, 180.23 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03813e5f0fb04e5a8db5db97fe9b1d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f58335b6ffd4eb9b359de4cff595afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.56 seconds, 320.88 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8de1b2a648245b2acb0c9374adbcb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04c90f5626249f882ed2afac8467d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.50 seconds, 332.30 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45b6cf29db5464491d7e38f17f11337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a14050914164be8aab5013be33967b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.48 seconds, 338.84 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872281235fe44ff2a42c176a07742d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d71ac0d2a4744e0af12819d30180867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.44 seconds, 347.85 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a23f165a787405ba65c7888e329b772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70169fcfa8344933a0ee6a3c5e905f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.42 seconds, 351.25 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af532d13dc7d485395224b5827a5a3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a21d95a1ca7434f8eb7e0c133554bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.41 seconds, 355.10 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeecfedaab5949f681a784bdc08873b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31f2351cf8041a485e94965448e1a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.48 seconds, 337.93 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63047bdbe5ab4825a673c74fbdf451c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cf24d2c09b49e4a6f12feb29cdc583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.46 seconds, 342.71 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaab1cb793854c5face2de8bdea6f415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf137779cb2046898d75186a4e480a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.46 seconds, 343.18 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053a7f538f9f47e3831f68f9681f336f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e6ee000b3742448015dcf478cb0bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.51 seconds, 330.23 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee0d3a3937c438ea890c7bf24220ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f1a0870f8649b8bb7442d8ca034fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.51 seconds, 330.71 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7897008597d4176868821a3249c92fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d149af30604f12b7bc50f06062a2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.57 seconds, 318.17 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ceb49518bc047348d14490e0e9044bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5a0273fea04dcdb45972ef95a9287d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.49 seconds, 335.23 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c72b6220a78442eaa87eca9c872d77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18daba9c335c4edd99191a80cdac81e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.47 seconds, 340.15 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d549c7ec5f5444c6a10904494c4bfb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fe5380b44348569cbfa8107666d69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.44 seconds, 346.56 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "for i in list_method:\n",
    "    for num in range(len(list_gen_summary)):\n",
    "        rouge_1_list = []\n",
    "        rouge_2_list = []\n",
    "        rouge_l_list = []\n",
    "        gold_list = []\n",
    "        gen_list = []\n",
    "        # print(num)\n",
    "        for idx in range(500):\n",
    "            gold = gold_summary_df.loc[idx, list_gold_summary[num]]\n",
    "            gen = result_all_df[i].loc[idx, list_gen_summary[num]]\n",
    "            rouge_1 = py_rouge_scores(gold, gen)['rouge-1']['f']\n",
    "            rouge_2 = py_rouge_scores(gold, gen)['rouge-2']['f']\n",
    "            rouge_l = py_rouge_scores(gold, gen)['rouge-l']['f']\n",
    "            rouge_1_list.append(rouge_1)\n",
    "            rouge_2_list.append(rouge_2)\n",
    "            rouge_l_list.append(rouge_l)\n",
    "            gold_list.append(gold)\n",
    "            gen_list.append(gen)\n",
    "            # print(len(rouge_1_list))\n",
    "        P, R, F1 = score(gold_list, gen_list, lang=\"en\", verbose=True)\n",
    "        bert_score = F1.tolist()\n",
    "        result_all_df[i][f\"gen{num+1}_rouge_1\"] = rouge_1_list\n",
    "        result_all_df[i][f\"gen{num+1}_rouge_2\"] = rouge_2_list\n",
    "        result_all_df[i][f\"gen{num+1}_rouge_l\"] = rouge_l_list\n",
    "        result_all_df[i][f\"gen{num+1}_bert_score\"] = bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91c6fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>gen_summary1</th>\n",
       "      <th>gen_summary2</th>\n",
       "      <th>gen_summary3</th>\n",
       "      <th>gen1_rouge_1</th>\n",
       "      <th>gen1_rouge_2</th>\n",
       "      <th>gen1_rouge_l</th>\n",
       "      <th>gen1_bert_score</th>\n",
       "      <th>gen2_rouge_1</th>\n",
       "      <th>gen2_rouge_2</th>\n",
       "      <th>gen2_rouge_l</th>\n",
       "      <th>gen2_bert_score</th>\n",
       "      <th>gen3_rouge_1</th>\n",
       "      <th>gen3_rouge_2</th>\n",
       "      <th>gen3_rouge_l</th>\n",
       "      <th>gen3_bert_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.317362</td>\n",
       "      <td>0.891681</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0.239912</td>\n",
       "      <td>0.890968</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.394919</td>\n",
       "      <td>0.884799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
       "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
       "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.466322</td>\n",
       "      <td>0.910078</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.444932</td>\n",
       "      <td>0.917976</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.466024</td>\n",
       "      <td>0.919479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.971663</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.698384</td>\n",
       "      <td>0.963978</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.549823</td>\n",
       "      <td>0.936696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1# celebrates Brian's birthday and danc...</td>\n",
       "      <td>#Person1# celebrates Brian's birthday and danc...</td>\n",
       "      <td>#Person1# celebrates Brian's birthday and danc...</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292332</td>\n",
       "      <td>0.903291</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>0.913248</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.343960</td>\n",
       "      <td>0.919319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1# and #Person2# are in the Olympic sta...</td>\n",
       "      <td>#Person1# and #Person2# are in the Olympic sta...</td>\n",
       "      <td>#Person1# and #Person2# are in the Olympic sta...</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.411817</td>\n",
       "      <td>0.899916</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.437425</td>\n",
       "      <td>0.927322</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.411817</td>\n",
       "      <td>0.904353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_495</td>\n",
       "      <td>Jack invites Charlie to come to his house and ...</td>\n",
       "      <td>Jack invites Charlie to come to his house and ...</td>\n",
       "      <td>Jack invites Charlie to come to his house and ...</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.672541</td>\n",
       "      <td>0.954458</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.592425</td>\n",
       "      <td>0.946067</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.576319</td>\n",
       "      <td>0.935164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2# tells #Person1# how #Person 2# got i...</td>\n",
       "      <td>#Person2# tells #Person1# how #Person 2# got i...</td>\n",
       "      <td>#Person2# tells #Person1# how #Person 2# got i...</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.663958</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.285779</td>\n",
       "      <td>0.889773</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.315593</td>\n",
       "      <td>0.921176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_497</td>\n",
       "      <td>Alice shows #Person1# how to use the washing m...</td>\n",
       "      <td>Alice shows #Person1# how to use the washing m...</td>\n",
       "      <td>Alice shows #Person1# how to use the washing m...</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.389635</td>\n",
       "      <td>0.899229</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.400312</td>\n",
       "      <td>0.888136</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.390688</td>\n",
       "      <td>0.886449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_498</td>\n",
       "      <td>Matthew and Steve haven't seen each other for ...</td>\n",
       "      <td>Matthew and Steve haven't seen each other for ...</td>\n",
       "      <td>Matthew and Steve haven't seen each other for ...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.463273</td>\n",
       "      <td>0.905874</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.512569</td>\n",
       "      <td>0.919481</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.526070</td>\n",
       "      <td>0.917013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>test_499</td>\n",
       "      <td>Frank tells Betsy he got a promotion and invit...</td>\n",
       "      <td>Frank tells Betsy he got a promotion and invit...</td>\n",
       "      <td>Frank tells Betsy he got a promotion and invit...</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321829</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353044</td>\n",
       "      <td>0.929288</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.345231</td>\n",
       "      <td>0.936936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                       gen_summary1  \\\n",
       "0      test_0  #Person1# asks Ms. Dawson to take a dictation ...   \n",
       "1      test_1  #Person2# got stuck in traffic again. #Person1...   \n",
       "2      test_2  #Person1# tells Kate that Masha and Hero are g...   \n",
       "3      test_3  #Person1# celebrates Brian's birthday and danc...   \n",
       "4      test_4  #Person1# and #Person2# are in the Olympic sta...   \n",
       "..        ...                                                ...   \n",
       "495  test_495  Jack invites Charlie to come to his house and ...   \n",
       "496  test_496  #Person2# tells #Person1# how #Person 2# got i...   \n",
       "497  test_497  Alice shows #Person1# how to use the washing m...   \n",
       "498  test_498  Matthew and Steve haven't seen each other for ...   \n",
       "499  test_499  Frank tells Betsy he got a promotion and invit...   \n",
       "\n",
       "                                          gen_summary2  \\\n",
       "0    #Person1# asks Ms. Dawson to take a dictation ...   \n",
       "1    #Person2# got stuck in traffic again. #Person1...   \n",
       "2    #Person1# tells Kate that Masha and Hero are g...   \n",
       "3    #Person1# celebrates Brian's birthday and danc...   \n",
       "4    #Person1# and #Person2# are in the Olympic sta...   \n",
       "..                                                 ...   \n",
       "495  Jack invites Charlie to come to his house and ...   \n",
       "496  #Person2# tells #Person1# how #Person 2# got i...   \n",
       "497  Alice shows #Person1# how to use the washing m...   \n",
       "498  Matthew and Steve haven't seen each other for ...   \n",
       "499  Frank tells Betsy he got a promotion and invit...   \n",
       "\n",
       "                                          gen_summary3  gen1_rouge_1  \\\n",
       "0    #Person1# asks Ms. Dawson to take a dictation ...      0.350000   \n",
       "1    #Person2# got stuck in traffic again. #Person1...      0.400000   \n",
       "2    #Person1# tells Kate that Masha and Hero are g...      0.871795   \n",
       "3    #Person1# celebrates Brian's birthday and danc...      0.342857   \n",
       "4    #Person1# and #Person2# are in the Olympic sta...      0.344828   \n",
       "..                                                 ...           ...   \n",
       "495  Jack invites Charlie to come to his house and ...      0.689655   \n",
       "496  #Person2# tells #Person1# how #Person 2# got i...      0.611111   \n",
       "497  Alice shows #Person1# how to use the washing m...      0.387097   \n",
       "498  Matthew and Steve haven't seen each other for ...      0.428571   \n",
       "499  Frank tells Betsy he got a promotion and invit...      0.307692   \n",
       "\n",
       "     gen1_rouge_2  gen1_rouge_l  gen1_bert_score  gen2_rouge_1  gen2_rouge_2  \\\n",
       "0        0.051282      0.317362         0.891681      0.426966      0.160920   \n",
       "1        0.052632      0.466322         0.910078      0.486486      0.171429   \n",
       "2        0.702703      0.892000         0.971663      0.650000      0.526316   \n",
       "3        0.000000      0.292332         0.903291      0.466667      0.142857   \n",
       "4        0.148148      0.411817         0.899916      0.444444      0.160000   \n",
       "..            ...           ...              ...           ...           ...   \n",
       "495      0.296296      0.672541         0.954458      0.533333      0.214286   \n",
       "496      0.294118      0.663958         0.963076      0.277778      0.058824   \n",
       "497      0.166667      0.389635         0.899229      0.484848      0.187500   \n",
       "498      0.222222      0.463273         0.905874      0.507463      0.276923   \n",
       "499      0.000000      0.321829         0.918699      0.457143      0.000000   \n",
       "\n",
       "     gen2_rouge_l  gen2_bert_score  gen3_rouge_1  gen3_rouge_2  gen3_rouge_l  \\\n",
       "0        0.239912         0.890968      0.425000      0.230769      0.394919   \n",
       "1        0.444932         0.917976      0.514286      0.181818      0.466024   \n",
       "2        0.698384         0.963978      0.634146      0.205128      0.549823   \n",
       "3        0.400809         0.913248      0.555556      0.176471      0.343960   \n",
       "4        0.437425         0.927322      0.413793      0.148148      0.411817   \n",
       "..            ...              ...           ...           ...           ...   \n",
       "495      0.592425         0.946067      0.580645      0.275862      0.576319   \n",
       "496      0.285779         0.889773      0.291667      0.130435      0.315593   \n",
       "497      0.400312         0.888136      0.441176      0.212121      0.390688   \n",
       "498      0.512569         0.919481      0.584615      0.412698      0.526070   \n",
       "499      0.353044         0.929288      0.511628      0.146341      0.345231   \n",
       "\n",
       "     gen3_bert_score  \n",
       "0           0.884799  \n",
       "1           0.919479  \n",
       "2           0.936696  \n",
       "3           0.919319  \n",
       "4           0.904353  \n",
       "..               ...  \n",
       "495         0.935164  \n",
       "496         0.921176  \n",
       "497         0.886449  \n",
       "498         0.917013  \n",
       "499         0.936936  \n",
       "\n",
       "[500 rows x 16 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_all_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbc6e378-8183-4ee9-8885-bc6c778845c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all_df[1].to_excel(\"result.xlsx\",\n",
    "             sheet_name='1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36e1fac9-a7d0-430e-ba87-d99c0c11696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, total_method+1):\n",
    "    with pd.ExcelWriter('result.xlsx',\n",
    "                        mode='a') as writer:  \n",
    "        result_all_df[i].to_excel(writer, sheet_name=f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f706a315-1e89-4d98-8c1a-d7df557aba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# gen_dict = {}\n",
    "# for i in list_method:\n",
    "#     metric = {}\n",
    "#     gold_1 = gold_summary_df['summary1'].tolist()\n",
    "#     gold_2 = gold_summary_df['summary2'].tolist()\n",
    "#     gold_3 = gold_summary_df['summary3'].tolist()\n",
    "#     gen_1 = result_all_df[i]['gen_summary1'].tolist()\n",
    "#     gen_2 = result_all_df[i]['gen_summary2'].tolist()\n",
    "#     gen_3 = result_all_df[i]['gen_summary3'].tolist()\n",
    "#     P_1, R_1, F1_1 = score(gold_1, gen_1, lang=\"en\", verbose=True)\n",
    "#     P_2, R_2, F1_2 = score(gold_2, gen_2, lang=\"en\", verbose=True)\n",
    "#     P_3, R_3, F1_3 = score(gold_3, gen_3, lang=\"en\", verbose=True)\n",
    "#     metric = {'bert_score_1' : F1_1,\n",
    "#               'bert_score_2' : F1_2,\n",
    "#               'bert_score_3' : F1_3}\n",
    "#     gen_dict[i] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02f1883f-c753-47fa-b3a9-0a6188e666b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in list_method:\n",
    "#     print(name_method[str(i)])\n",
    "#     print((torch.mean(gen_dict[i]['bert_score_1']).item() + torch.mean(gen_dict[i]['bert_score_1']).item() + torch.mean(gen_dict[i]['bert_score_1']).item())/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39fd6800-8230-467c-b89e-730ed79e8a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9195)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c8a84ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold Summary:  #Person2# is checking out and asks #Person1# for the bill. #Person1# gives #Person2# a wrong bill at first then corrects it.\n",
      "Gold Topic:  bill\n",
      "======================================================================================================================================================\n",
      "Experiment:  1_bart_noprompt\n",
      "gen_summary1 #Person1# helps #Person2# check out and finds the charge for laundry service on Nov. 20th has been added to someone else's. They'll correct the bill.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Experiment:  2_bart_topic\n",
      "gen_summary1 #Person2# is checking out and finds the bill is wrong. #Person1# will correct it with the department concerned.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Experiment:  3_bart_length\n",
      "gen_summary1 #Person1# helps #Person2# check out and finds the charge for laundry service on Nov. 20th has been added to someone else's bill.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Experiment:  4_bart_topic_length\n",
      "gen_summary1 #Person2# is checking out and finds the bill has been wrong. #Person1# apologizes and will correct the bill.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_example = 7\n",
    "gen_summary_num = 0\n",
    "\n",
    "list_gold_summary = ['summary1', 'summary2', 'summary3']\n",
    "list_gold_topic = ['topic1', 'topic2', 'topic3']\n",
    "list_gen_summary = ['gen_summary1', 'gen_summary2', 'gen_summary3']\n",
    "\n",
    "print(\"Gold Summary: \", gold_summary_df.loc[num_example, list_gold_summary[gen_summary_num]])\n",
    "print(\"Gold Topic: \", gold_summary_df.loc[num_example, list_gold_topic[gen_summary_num]])\n",
    "print(\"=\"*150)\n",
    "for num_method in list_method:\n",
    "    print(\"Experiment: \", name_method[str(num_method)])\n",
    "    \n",
    "    # print(\"gen_summary1: \", result_all_df[num_method].loc[num_example, 'gen_summary1'])\n",
    "    # print(\"gen_summary2: \", result_all_df[num_method].loc[num_example, 'gen_summary2'])\n",
    "    # print(\"gen_summary3: \", result_all_df[num_method].loc[num_example, 'gen_summary3'])\n",
    "    # print(\"-\"*150)\n",
    "    \n",
    "    print(list_gen_summary[gen_summary_num], result_all_df[num_method].loc[num_example, list_gen_summary[gen_summary_num]])\n",
    "    print(\"-\"*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c497835",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_prompt = \"#Person2# is checking out and finds the bill is wrong. #Person1# will correct it with the department concerned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b71d7e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(length_prompt.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f18e142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find the matching substrings in 2 strings.\n",
    ":parameter\n",
    "    :param a: string - raw text\n",
    "    :param b: string - raw text\n",
    ":return\n",
    "    2 lists used in to display matches\n",
    "'''\n",
    "def utils_split_sentences(a, b):\n",
    "    ## find clean matches\n",
    "    match = difflib.SequenceMatcher(isjunk=None, a=a, b=b, autojunk=True)\n",
    "    lst_match = [block for block in match.get_matching_blocks() if block.size > 20]\n",
    "\n",
    "    ## difflib didn't find any match\n",
    "    if len(lst_match) == 0:\n",
    "        lst_a, lst_b = nltk.sent_tokenize(a), nltk.sent_tokenize(b)\n",
    "\n",
    "    ## work with matches\n",
    "    else:\n",
    "        first_m, last_m = lst_match[0], lst_match[-1]\n",
    "\n",
    "        ### a\n",
    "        string = a[0 : first_m.a]\n",
    "        lst_a = [t for t in nltk.sent_tokenize(string)]\n",
    "        for n in range(len(lst_match)):\n",
    "            m = lst_match[n]\n",
    "            string = a[m.a : m.a+m.size]\n",
    "            lst_a.append(string)\n",
    "            if n+1 < len(lst_match):\n",
    "                next_m = lst_match[n+1]\n",
    "                string = a[m.a+m.size : next_m.a]\n",
    "                lst_a = lst_a + [t for t in nltk.sent_tokenize(string)]\n",
    "            else:\n",
    "                break\n",
    "        string = a[last_m.a+last_m.size :]\n",
    "        lst_a = lst_a + [t for t in nltk.sent_tokenize(string)]\n",
    "\n",
    "        ### b\n",
    "        string = b[0 : first_m.b]\n",
    "        lst_b = [t for t in nltk.sent_tokenize(string)]\n",
    "        for n in range(len(lst_match)):\n",
    "            m = lst_match[n]\n",
    "            string = b[m.b : m.b+m.size]\n",
    "            lst_b.append(string)\n",
    "            if n+1 < len(lst_match):\n",
    "                next_m = lst_match[n+1]\n",
    "                string = b[m.b+m.size : next_m.b]\n",
    "                lst_b = lst_b + [t for t in nltk.sent_tokenize(string)]\n",
    "            else:\n",
    "                break\n",
    "        string = b[last_m.b+last_m.size :]\n",
    "        lst_b = lst_b + [t for t in nltk.sent_tokenize(string)]\n",
    "\n",
    "    return lst_a, lst_b\n",
    "\n",
    "\n",
    "'''\n",
    "Highlights the matched strings in text.\n",
    ":parameter\n",
    "    :param a: string - raw text\n",
    "    :param b: string - raw text\n",
    "    :param both: bool - search a in b and, if True, viceversa\n",
    "    :param sentences: bool - if False matches single words\n",
    ":return\n",
    "    text html, it can be visualized on notebook with display(HTML(text))\n",
    "'''\n",
    "def display_string_matching(a, b, both=True, sentences=True, titles=[]):\n",
    "    if sentences is True:\n",
    "        lst_a, lst_b = utils_split_sentences(a, b)\n",
    "    else:\n",
    "        lst_a, lst_b = a.split(), b.split()\n",
    "\n",
    "    ## highlight a\n",
    "    first_text = []\n",
    "    for i in lst_a:\n",
    "        if re.sub(r'[^\\w\\s]', '', i.lower()) in [re.sub(r'[^\\w\\s]', '', z.lower()) for z in lst_b]:\n",
    "            first_text.append('<span style=\"background-color:rgba(255,215,0,0.1);\">' + i + '</span>')\n",
    "        else:\n",
    "            first_text.append(i)\n",
    "    first_text = ' '.join(first_text)\n",
    "\n",
    "    ## highlight b\n",
    "    second_text = []\n",
    "    if both is True:\n",
    "        for i in lst_b:\n",
    "            if re.sub(r'[^\\w\\s]', '', i.lower()) in [re.sub(r'[^\\w\\s]', '', z.lower()) for z in lst_a]:\n",
    "                second_text.append('<span style=\"background-color:rgba(255,215,0,0.1);\">' + i + '</span>')\n",
    "            else:\n",
    "                second_text.append(i)\n",
    "    else:\n",
    "        second_text.append(b)\n",
    "    second_text = ' '.join(second_text)\n",
    "\n",
    "    ## concatenate\n",
    "    if len(titles) > 0:\n",
    "        first_text = \"<strong>\"+titles[0]+\"</strong><br>\"+first_text\n",
    "    if len(titles) > 1:\n",
    "        second_text = \"<strong>\"+titles[1]+\"</strong><br>\"+second_text\n",
    "    else:\n",
    "        second_text = \"---\"*65+\"<br><br>\"+second_text\n",
    "    final_text = first_text +'<br><br>'+ second_text\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26510929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "list_method = list(range(1 ,total_method + 1))\n",
    "result_all_df = {}\n",
    "for i in list_method:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396155c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0c284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e24a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = display_string_matching(text_a, text_b, both=True, sentences=False, titles=[\"Full Text\", \"Actual Text\"])\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(match))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
